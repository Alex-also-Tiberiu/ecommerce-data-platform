# Task checklist day-by-day (realistic)

## ğŸ—“ï¸ Week 1 â€” Foundations (Kafka + Java)

### Day 1

* define `OrderCreated` event schema
* fields: `order_id`, `customer_id`, `items`, `price`, `timestamp`

### Day 2

* Spring Boot producer
* endpoint `/orders`
* produce event to Kafka

### Day 3

* setup Kafka (docker-compose)
* topic with partitions >1

### Day 4

* idempotency
* logging
* retry

### Day 5

* manual tests
* basic documentation

ğŸ¯ Output: real events flowing

---

## ğŸ—“ï¸ Week 2 â€” Spark (processing)

### Day 6

* setup Spark local
* read static data (file)

### Day 7

* Spark batch job
* basic transformations

### Day 8

* read from Kafka
* JSON parsing

### Day 9

* aggregations (orders per day, revenue)

### Day 10

* write to Postgres
* error handling

ğŸ¯ Output: transformed and persisted data

---

## ğŸ—“ï¸ Week 3 â€” Airflow (orchestration)

### Day 11

* Airflow concepts (DAG, task, operator)

### Day 12

* first static DAG

### Day 13

* Spark batch task

### Day 14

* retry + scheduling

### Day 15

* logging + basic alerting

ğŸ¯ Output: controlled and observable pipeline

---

## ğŸ—“ï¸ Week 4 â€” Cleanup & quality

### Day 16

* warehouse schema (fact + dimension)

### Day 17

* data quality checks (null, duplicates)

### Day 18

* analytics queries ready

### Day 19

* architecture documentation

### Day 20

* README refinement + diagram

ğŸ¯ Output: project completed
